FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535520000e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000005960464480000e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=4 17 5 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (4, 5, 9.99999977648258210000e-003) (4, 5, 9.99999977648258210000e-003) (4, 5, 9.99999977648258210000e-003) (4, 5, 9.99999977648258210000e-003) (4, 5, 9.99999977648258210000e-003) (4, 5, 9.99999977648258210000e-003) (4, 5, 9.99999977648258210000e-003) (4, 5, 9.99999977648258210000e-003) (4, 5, 9.99999977648258210000e-003) (4, 5, 9.99999977648258210000e-003) (4, 5, 9.99999977648258210000e-003) (4, 5, 9.99999977648258210000e-003) (4, 5, 9.99999977648258210000e-003) (4, 5, 9.99999977648258210000e-003) (4, 5, 9.99999977648258210000e-003) (4, 5, 9.99999977648258210000e-003) (0, 0, 0.00000000000000000000e+000) (17, 5, 9.99999977648258210000e-003) (17, 5, 9.99999977648258210000e-003) (17, 5, 9.99999977648258210000e-003) (17, 5, 9.99999977648258210000e-003) (0, 0, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 4.54101562500000000000e-002) (1, -7.22900405526161190000e-002) (2, -1.94396972656250000000e-002) (3, 6.05407729744911190000e-002) (0, -8.33740271627902980000e-003) (1, -7.47497603297233580000e-002) (2, -7.67822265625000000000e-002) (3, 9.43542495369911190000e-002) (0, -9.78698730468750000000e-002) (1, -3.37036140263080600000e-002) (2, 5.81054687500000000000e-002) (3, -1.05651859194040300000e-002) (0, 9.61425825953483580000e-002) (1, 1.09497075900435450000e-002) (2, 5.07263205945491790000e-002) (3, 1.18957525119185450000e-002) (0, 8.75610336661338810000e-002) (1, 8.09753462672233580000e-002) (2, 4.56542968750000000000e-002) (3, -1.59301760140806440000e-003) (0, 5.51574714481830600000e-002) (1, 7.37854018807411190000e-002) (2, -5.04089370369911190000e-002) (3, -6.79077133536338810000e-002) (0, 3.98681648075580600000e-002) (1, -4.44335956126451490000e-003) (2, 5.69641105830669400000e-002) (3, 9.07165557146072390000e-002) (0, 2.52929683774709700000e-002) (1, -5.52062988281250000000e-002) (2, 2.43530273437500000000e-002) (3, -5.16357421875000000000e-002) (0, -4.23278808593750000000e-002) (1, 7.74230957031250000000e-002) (2, -9.99633818864822390000e-002) (3, -8.81347656250000000000e-002) (0, 6.14929199218750000000e-002) (1, 8.49182158708572390000e-002) (2, 1.48193361237645150000e-002) (3, 7.33032226562500000000e-002) (0, -9.28772017359733580000e-002) (1, 1.64428707212209700000e-002) (2, 4.04479987919330600000e-002) (3, 5.97045905888080600000e-002) (0, -1.34033206850290300000e-002) (1, -2.35656742006540300000e-002) (2, 2.18688976019620900000e-002) (3, -3.86779792606830600000e-002) (0, 5.38879409432411190000e-002) (1, -7.11364746093750000000e-002) (2, 8.95629897713661190000e-002) (3, 1.96105968207120900000e-002) (0, -1.41357425600290300000e-002) (1, -6.06933608651161190000e-002) (2, 5.82092292606830600000e-002) (3, 5.62988296151161190000e-002) (0, 2.02087406069040300000e-002) (1, 8.62426757812500000000e-002) (2, 1.78894046694040300000e-002) (3, -7.53540024161338810000e-002) (0, -7.34680220484733580000e-002) (1, -2.73437500000000000000e-002) (2, -7.58178755640983580000e-002) (3, -3.57299819588661190000e-002) (4, -3.30688469111919400000e-002) (5, 6.93420395255088810000e-002) (6, 9.32922363281250000000e-002) (7, -5.92895522713661190000e-002) (8, 2.30712885968387130000e-003) (9, 2.11059581488370900000e-002) (10, 8.52050818502902980000e-003) (11, 5.10375984013080600000e-002) (12, 5.24902367033064370000e-004) (13, -5.29602058231830600000e-002) (14, -5.56762702763080600000e-002) (15, 7.66906738281250000000e-002) (16, -9.70764160156250000000e-002) (17, 6.62475600838661190000e-002) (18, 1.41601562500000000000e-002) (19, 6.48559555411338810000e-002) (20, -9.48791503906250000000e-002) (4, 8.02062973380088810000e-002) (5, -5.15197776257991790000e-002) (6, 1.96228027343750000000e-002) (7, -9.13330093026161190000e-002) (8, 4.29931655526161190000e-002) (9, 8.98437481373548510000e-003) (10, -1.58996582031250000000e-002) (11, -4.57763671875000000000e-004) (12, -4.93347160518169400000e-002) (13, -5.45105002820491790000e-002) (14, -5.13916043564677240000e-003) (15, -9.00817885994911190000e-002) (16, -1.89758297055959700000e-002) (17, 1.62963871844112870000e-003) (18, 8.98803696036338810000e-002) (19, -8.06640610098838810000e-002) (20, 1.50451660156250000000e-002) (4, 7.55981430411338810000e-002) (5, 5.12146018445491790000e-002) (6, -4.83581535518169400000e-002) (7, -2.88391113281250000000e-002) (8, 4.22668457031250000000e-002) (9, 6.37329146265983580000e-002) (10, -7.61901885271072390000e-002) (11, -1.62780769169330600000e-002) (12, -5.71655295789241790000e-002) (13, -2.89001464843750000000e-002) (14, -9.70153808593750000000e-002) (15, -4.31945808231830600000e-002) (16, 4.83581535518169400000e-002) (17, -8.97399932146072390000e-002) (18, -7.19604492187500000000e-002) (19, -7.52868652343750000000e-002) (20, -9.66857895255088810000e-002) (4, 5.71899442002177240000e-003) (5, 5.17456047236919400000e-002) (6, -4.96826171875000000000e-002) (7, -4.45129387080669400000e-002) (8, -9.52026396989822390000e-002) (9, 5.99426291882991790000e-002) (10, -7.42187490686774250000e-003) (11, 7.84973129630088810000e-002) (12, 3.52050773799419400000e-002) (13, 2.39379890263080600000e-002) (14, 7.44384750723838810000e-002) (15, -6.92138681188225750000e-003) (16, -3.39294448494911190000e-002) (17, -5.77270500361919400000e-002) (18, -1.76574718207120900000e-002) (19, 9.34936553239822390000e-002) (20, -4.62219230830669400000e-002) 
